import streamlit as st
import requests
import os
from datetime import datetime
from urllib.parse import quote

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(page_title="–ù–æ–≤–æ—Å—Ç–∏ –í—Å–µ–ª–µ–Ω–Ω–æ–π Disney", layout="wide")

st.markdown("""
<style>
    .stApp { background-color: #f0f2f6; }
    body, p, .st-emotion-cache-16txtl3, .st-emotion-cache-1629p8f p, .st-emotion-cache-1xarl3l, h1, h2, h3, h4, h5, h6 {
        color: #111111 !important;
    }
    .st-emotion-cache-16txtl3 { padding-top: 2rem; }
</style>
""", unsafe_allow_html=True)

# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π ---
@st.cache_data(ttl=3600)
def fetch_news(search_query):
    api_key = os.getenv("NEWS_API_KEY")
    if not api_key:
        return None, "–ö–ª—é—á API –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω."
    
    encoded_query = quote(search_query)
    
    url = (f"https://newsapi.org/v2/everything?"
           f"qInTitle={encoded_query}&"
           f"language=ru&"
           f"sortBy=publishedAt&"
           f"apiKey={api_key}")
    
    try:
        response = requests.get(url)
        if response.status_code == 200:
            return response.json().get("articles", []), None
        else:
            return None, f"–û—à–∏–±–∫–∞ API. –°—Ç–∞—Ç—É—Å: {response.status_code}"
    except Exception as e:
        return None, f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}"

# === –ò–ù–¢–ï–†–§–ï–ô–° –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø ===
st.title("üåê –î–∞–π–¥–∂–µ—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤—Å–µ–ª–µ–Ω–Ω–æ–π Disney")
st.divider()

# --- –†–∞–∑–¥–µ–ª "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏" ---
st.header("üî• –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏")

# –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
relevant_keywords = (
    'Disney OR "The Walt Disney Company" OR '
    'Pixar OR "Pixar Animation Studios" OR '
    'Marvel OR "Marvel Studios" OR MCU OR '
    'Lucasfilm OR "Star Wars" OR "–ò–Ω–¥–∏–∞–Ω–∞ –î–∂–æ–Ω—Å" OR '
    '"20th Century Studios" OR "Searchlight Pictures" OR '
    '"National Geographic" OR '
    'ESPN OR '
    '"Walt Disney Animation Studios" OR '
    'Disneyland OR "Disneyland Resort" OR '
    '"Walt Disney World" OR '
    '"Disney Cruise Line" OR '
    '"Inside Out" OR "–ì–æ–ª–æ–≤–æ–ª–æ–º–∫–∞" OR '
    '"The Mandalorian & Grogu" OR "–ú–∞–Ω–¥–∞–ª–æ—Ä–µ—Ü" OR '
    '"Moana" OR "–ú–æ–∞–Ω–∞" OR '
    '"Zootopia" OR "–ó–≤–µ—Ä–æ–ø–æ–ª–∏—Å" OR '
    '"Frozen" OR "–•–æ–ª–æ–¥–Ω–æ–µ —Å–µ—Ä–¥—Ü–µ"'
)

with st.spinner("–ó–∞–≥—Ä—É–∂–∞—é —Å–∞–º—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏..."):
    latest_articles, error = fetch_news(relevant_keywords)
    if error:
        st.error(error)
    elif latest_articles:
        for article in latest_articles[:7]: # 7 –Ω–æ–≤–æ—Å—Ç–µ–π 
            st.subheader(article['title'])
            try:
                date_published = datetime.fromisoformat(article['publishedAt'].replace('Z', '')).strftime('%d.%m.%Y %H:%M')
            except:
                date_published = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            
            st.caption(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {article['source']['name']} | –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {date_published}")
            st.markdown(f"[*–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ...*]({article['url']})")
            st.divider()
    else:
        st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ç–µ–º–∞–º Disney.")

# --- –†–∞–∑–¥–µ–ª "–ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π" ---
st.header("üîç –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π")
search_term = st.text_input("–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Avatar 4' –∏–ª–∏ 'Bob Iger'):", "Toy Story 5")

if st.button("–ù–∞–π—Ç–∏"):
    if not search_term:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞.")
    else:
        with st.spinner(f"–ò—â—É –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{search_term}'..."):
            articles, error = fetch_news(search_term)
            if error:
                st.error(error)
            elif not articles:
                st.info(f"–ù–æ–≤–æ—Å—Ç–µ–π –ø–æ –∑–∞–ø—Ä–æ—Å—É '{search_term}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            else:
                st.success(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{search_term}':")
                for article in articles[:10]:
                    st.subheader(article['title'])
                    try:
                        date_published = datetime.fromisoformat(article['publishedAt'].replace('Z', '')).strftime('%d.%m.%Y %H:%M')
                    except:
                        date_published = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

                    st.caption(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {article['source']['name']} | –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {date_published}")
                    if article['description']:
                      st.write(article['description'])
                    st.markdown(f"[*–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ...*]({article['url']})")
                    st.divider()

